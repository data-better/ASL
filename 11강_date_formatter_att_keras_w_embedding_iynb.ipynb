{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11강-date_formatter_att_keras_w_embedding.iynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-better/ASL/blob/master/11%EA%B0%95_date_formatter_att_keras_w_embedding_iynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9CqnWctXVE",
        "outputId": "b49621a2-cee2-4df1-eab9-88a343ae4a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import time\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "tf.enable_eager_execution() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4z5hM8ttZZe",
        "outputId": "5778f8fa-e76f-4c1b-a7e3-a2cda2ba9e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def padding(chars, maxlen):\n",
        "    if len(chars) < maxlen:\n",
        "        return chars + ' ' * (maxlen - len(chars))\n",
        "    else:\n",
        "        return chars[:maxlen]\n",
        "\n",
        "def gen_date():\n",
        "    rnd = int(np.random.uniform(low = 1000000000, high = 2000000000))\n",
        "    timestamp = datetime.fromtimestamp(rnd)\n",
        "    return str(timestamp.strftime('%Y-%B-%d %a')) # '%Y-%B-%d %H:%M:%S'\n",
        "\n",
        "def format_date(x):\n",
        "    return str(datetime.strptime(x, '%Y-%B-%d %a').strftime('%m/%d/%Y, %A')).lower() #'%H%M%S:%Y%m%d'\n",
        "\n",
        "N = 10000\n",
        "N_train = int(N * .9)\n",
        "N_validation = N - N_train\n",
        "\n",
        "in_seq_len = 32\n",
        "out_seq_len = 32\n",
        "\n",
        "added = set()\n",
        "questions = []\n",
        "answers = []\n",
        "answers_y = []\n",
        "\n",
        "while len(questions) < N:\n",
        "    if len(questions) % 1000 == 0:\n",
        "        print('i = {}'.format(len(questions)))\n",
        "    a = gen_date()\n",
        "    if a in added:\n",
        "        continue\n",
        "    question = '[{}]'.format(a)\n",
        "    answer = '[' + str(format_date(a)) + ']'\n",
        "    answer = padding(answer, out_seq_len)\n",
        "    answer_y = str(format_date(a)) + ']'\n",
        "    answer_y = padding(answer_y, out_seq_len)\n",
        "    \n",
        "    added.add(a)\n",
        "    questions.append(question)\n",
        "    answers.append(answer)\n",
        "    answers_y.append(answer_y)\n",
        "\n",
        "chars = list(set(''.join(questions)))\n",
        "chars.extend(['[', ']']) # Start and End of Expression\n",
        "chars.extend(list(set(''.join(answers))))\n",
        "chars = np.sort(list(set(chars)))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "i = 1000\n",
            "i = 2000\n",
            "i = 3000\n",
            "i = 4000\n",
            "i = 5000\n",
            "i = 6000\n",
            "i = 7000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 8000\n",
            "i = 9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyNN4sxVMLe3",
        "outputId": "98bfee09-8520-4ff8-ca4d-d18b3c1eb669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char_indices['[']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iod24gRcvC3J",
        "outputId": "dcf2c208-45d5-452a-b0fd-fb8d51284cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(questions[:10])\n",
        "print(answers[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[2023-May-05 Fri]', '[2030-July-14 Sun]', '[2015-August-28 Fri]', '[2024-May-27 Mon]', '[2031-June-04 Wed]', '[2028-February-28 Mon]', '[2012-September-18 Tue]', '[2010-November-18 Thu]', '[2013-November-20 Wed]', '[2023-March-10 Fri]']\n",
            "['[05/05/2023, friday]            ', '[07/14/2030, sunday]            ', '[08/28/2015, friday]            ', '[05/27/2024, monday]            ', '[06/04/2031, wednesday]         ', '[02/28/2028, monday]            ', '[09/18/2012, tuesday]           ', '[11/18/2010, thursday]          ', '[11/20/2013, wednesday]         ', '[03/10/2023, friday]            ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yaipnClbJqv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daM8UPF6vlkm"
      },
      "source": [
        "# Src seq\n",
        "X = np.zeros((len(questions), in_seq_len), dtype=np.integer)\n",
        "# Trg seq\n",
        "Y = np.zeros((len(questions), out_seq_len), dtype=np.integer)\n",
        "# Delayed trg seq\n",
        "Z = np.zeros((len(questions), out_seq_len), dtype=np.integer)\n",
        "\n",
        "for i in range(N):\n",
        "    for t, char in enumerate(questions[i]):\n",
        "        X[i, t] = char_indices[char]\n",
        "    for t, char in enumerate(answers[i]):\n",
        "        Y[i, t] = char_indices[char]\n",
        "    for t, char in enumerate(answers_y[i]):\n",
        "        Z[i, t] = char_indices[char]\n",
        "    \n",
        "X_train, X_validation, Y_train, Y_validation, Z_train, Z_validation = \\\n",
        "    train_test_split(X, Y, Z, train_size=N_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5mbjwlZvnwz",
        "outputId": "c0138e7a-48af-4f9f-e10d-dba7a7c560f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Z_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5,  5,  3,  6,  7,  3,  6,  4,  5,  6,  1,  0, 31, 40, 34, 29, 26,\n",
              "       46, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAvH6Bypvs-K"
      },
      "source": [
        "def gen_test(N):\n",
        "    q = []\n",
        "    y = []\n",
        "    \n",
        "    for i in range(N):\n",
        "        question = gen_date()\n",
        "        answer_y = format_date(question)\n",
        "        q.append(question)\n",
        "        y.append(answer_y)\n",
        "    return(q,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhBi5NKhv2e0"
      },
      "source": [
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHd7ooDnySEW",
        "outputId": "26f1eaff-067a-4505-970e-6c06ab3d2a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SAFNb14zYoQ"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.CuDNNGRU(units,\n",
        "                      return_sequences = True,\n",
        "                      return_state = True,\n",
        "                      recurrent_initializer = 'glorot_uniform'\n",
        "                      )\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    #print('x in Encoder after embedding = {}'.format(x.shape))\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMbwilT3Uqh"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.CuDNNGRU(units,\n",
        "                      return_sequences = True,\n",
        "                      return_state = True,\n",
        "                      recurrent_initializer = 'glorot_uniform'\n",
        "                      )\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    # used for attention\n",
        "    self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "    self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # Process single token at a time\n",
        "    #enc_output: T* enc_units\n",
        "    #hidden: hidden in decoder\n",
        "    # Consider T as batch\n",
        "    #W1: enc_units * dec_unit\n",
        "    #W2: hidden * dec_unit\n",
        "    #V: dec_unit * 1\n",
        "    #attntion_weights: T * 1\n",
        "    #enc_output: enc_units * T\n",
        "    \n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "    score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "    # score: batch_size * T\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "    # attention_weights: batch_size * T\n",
        "    \n",
        "    context_vector = attention_weights * enc_output\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "    #context_vector: batch_size * hidden_size\n",
        "    x = self.embedding(x)\n",
        "    # x: batch_size * 1 * embedding_dim\n",
        "    #print('context vector size = {}'.format(context_vector.shape))\n",
        "    #print('x vector size = {}'.format(x.shape))\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    # x: batch_size * 1 * (hidden_size + embedding_dim)\n",
        "    \n",
        "    output, state = self.gru(x)\n",
        "    #output: batch_size * 1* hidden_size\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    #output: batch_size * hidden_size\n",
        "    x = self.fc(output)\n",
        "    #output: batch_size * vocab_size\n",
        "    \n",
        "    return x, state, attention_weights\n",
        "  \n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.dec_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zepMaq0ZkUX3"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder, char_indices, indices_char, max_len_inp, max_len_targ, hidden_units):\n",
        "  attention_plot = np.zeros((max_len_targ, max_len_inp))\n",
        "  inp = np.zeros((1, max_len_inp), dtype=np.integer)\n",
        "  for t, char in enumerate(sentence):\n",
        "    inp[0, t] = char_indices[char]\n",
        "  inp = tf.convert_to_tensor(inp)\n",
        "  \n",
        "  result = ''\n",
        "  hidden = [tf.zeros((1, hidden_units))]\n",
        "  enc_out, enc_hidden = encoder(inp, hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_inp = tf.expand_dims([char_indices['[']], 0)\n",
        "  \n",
        "  for t in range(max_len_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_inp, dec_hidden, enc_out)\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    \n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    \n",
        "    result += indices_char[predicted_id]\n",
        "    if indices_char[predicted_id] == ']':\n",
        "      return result, sentence, attention_plot\n",
        "    \n",
        "    dec_inp = tf.expand_dims([predicted_id], 0)\n",
        "    \n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aviB-1ybofa3"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize = (10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap = 'viridis')\n",
        "  fontdict = {'fontsize': 14}\n",
        "  \n",
        "  ax.set_xticklabels([''] + sentence, fontdict = fontdict, rotation = 90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEVb_1NZN7SV"
      },
      "source": [
        "def evaluate_some(n, encoder, decoder, char_indices, indices_char, max_len_inp, max_len_targ, hidden_units):\n",
        "  q, y = gen_test(n)\n",
        "  for i in range(n):\n",
        "    p, _, _ = evaluate(q[i], encoder, decoder, char_indices, indices_char, max_len_inp, max_len_targ, hidden_units)\n",
        "    p = p.strip()\n",
        "    iscorr = 1 if p == y[i] else 0\n",
        "    if iscorr == 1:\n",
        "      print(colors.ok + '☑' + colors.close, end=' ')\n",
        "    else:\n",
        "      print(colors.fail + '☒' + colors.close, end=' ')\n",
        "    print(\"{} = {}({})\".format(q[i], p, y[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27LnC04TLp_b"
      },
      "source": [
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 32\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(chars)\n",
        "vocab_tar_size = len(chars)\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8sM_6_7Mczn"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = real, logits = pred) * mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtrr69JNL9Q"
      },
      "source": [
        "import os\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer = optimizer,\n",
        "                                 encoder = encoder,\n",
        "                                 decoder = decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLppBoUKN3yq",
        "outputId": "40046330-4fee-4657-cfd4-339dfc71ea29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  \n",
        "  for batch in range(N_BATCH):\n",
        "    loss = 0\n",
        "    idx = np.arange(batch * BATCH_SIZE, (batch + 1) * BATCH_SIZE)\n",
        "    inp = X_train[idx, :]\n",
        "    targ = Y_train[idx, :]\n",
        "    #print('inp shape = {}'.format(inp.shape))\n",
        "    with tf.GradientTape() as tape:\n",
        "      enc_output, enc_hidden = encoder(inp, hidden)\n",
        "      dec_hidden = enc_hidden\n",
        "      dec_input = tf.expand_dims([char_indices['[']] * BATCH_SIZE, 1)\n",
        "      \n",
        "      # Teacher forcing\n",
        "      \n",
        "      for t in range(1, targ.shape[1]):\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "      \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    total_loss += batch_loss\n",
        "      \n",
        "    variables = encoder.variables + decoder.variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "      \n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "      \n",
        "    #if batch % 10 == 0:\n",
        "    #  print('Epoch {} Batch {} Loss: {:.6f}'.format(epoch +1, \n",
        "    #                                            batch, \n",
        "    #                                            batch_loss.numpy()))\n",
        "        \n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    evaluate_some(10, encoder, decoder, char_indices, indices_char, 32, 32, units)\n",
        "        \n",
        "  print('Epoch {} Loss {:.6f}, Elapsed_time ={:.2f} sec'.format(epoch + 1, \n",
        "                                                                total_loss / N_BATCH, \n",
        "                                                                time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.610379, Elapsed_time =217.43 sec\n",
            "Epoch 2 Loss 0.204183, Elapsed_time =218.60 sec\n",
            "Epoch 3 Loss 0.007149, Elapsed_time =218.91 sec\n",
            "Epoch 4 Loss 0.000253, Elapsed_time =218.39 sec\n",
            "Epoch 5 Loss 0.000108, Elapsed_time =219.30 sec\n",
            "Epoch 6 Loss 0.018136, Elapsed_time =219.00 sec\n",
            "Epoch 7 Loss 0.000247, Elapsed_time =218.32 sec\n",
            "Epoch 8 Loss 0.000083, Elapsed_time =218.11 sec\n",
            "Epoch 9 Loss 0.000048, Elapsed_time =217.30 sec\n",
            "\u001b[91m☒\u001b[0m 2027-May-26 Wed = 05/26/2027,dnednesday](05/26/2027, wednesday)\n",
            "\u001b[91m☒\u001b[0m 2008-March-28 Fri = 03/28/2008,iday](03/28/2008, friday)\n",
            "\u001b[91m☒\u001b[0m 2019-July-11 Thu = 07/11/2019,](07/11/2019, thursday)\n",
            "\u001b[91m☒\u001b[0m 2020-December-02 Wed = 12/02/2020,](12/02/2020, wednesday)\n",
            "\u001b[91m☒\u001b[0m 2032-March-28 Sun = 03/28/2032,turday](03/28/2032, sunday)\n",
            "\u001b[91m☒\u001b[0m 2016-January-08 Fri = 01/08/2016,iday](01/08/2016, friday)\n",
            "\u001b[91m☒\u001b[0m 2012-April-22 Sun = 04/22/2012,](04/22/2012, sunday)\n",
            "\u001b[91m☒\u001b[0m 2008-February-23 Sat = 02/23/2008,](02/23/2008, saturday)\n",
            "\u001b[91m☒\u001b[0m 2012-July-05 Thu = 07/05/2012,](07/05/2012, thursday)\n",
            "\u001b[91m☒\u001b[0m 2012-June-26 Tue = 06/26/2012,](06/26/2012, tuesday)\n",
            "Epoch 10 Loss 0.000032, Elapsed_time =219.25 sec\n",
            "Epoch 11 Loss 0.000023, Elapsed_time =217.01 sec\n",
            "Epoch 12 Loss 0.000017, Elapsed_time =217.51 sec\n",
            "Epoch 13 Loss 0.000013, Elapsed_time =217.17 sec\n",
            "Epoch 14 Loss 0.000011, Elapsed_time =216.25 sec\n",
            "Epoch 15 Loss 0.000008, Elapsed_time =217.82 sec\n",
            "Epoch 16 Loss 0.000007, Elapsed_time =217.93 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APS33YSNEthe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkvMB7IqccO",
        "outputId": "89f918b7-78fe-4c23-b17c-aab988caf206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "q, y = gen_test(1)\n",
        "result, sentence, _ = evaluate(q[0], encoder, decoder, char_indices, indices_char,32, 32)\n",
        "print('pred = {}, inp = {}'.format(result, sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c6c286586cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred = {}, inp = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gen_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5xg2eZAwT3-"
      },
      "source": [
        "evaluate_some(3, encoder, decoder, char_indices, indices_char,32, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99A9rFM6waai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}