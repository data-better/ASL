{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10강-sentiment_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-better/ASL/blob/master/10%EA%B0%95_sentiment_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUWPk3Q6WEcD"
      },
      "source": [
        "- [케라스 창시자에게 배우는 딥러닝: 파이썬과 케라스(keras)로 배우는 딥러닝]에도 나오는 예제\n",
        "- 인터넷 예시 참조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PclBfeA-XuSi",
        "outputId": "190b0ea8-c451-43b5-922b-9e02ca56e7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers, models, datasets\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w95BRIICPO3"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55Ha__A1YWNs"
      },
      "source": [
        "class Data:\n",
        "  def __init__(self, max_features = 10000, maxlen = 80):\n",
        "    #ValueError: Object arrays cannot be loaded when allow_pickle=False\n",
        "    #https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56062555\n",
        "    np_load_old = np.load\n",
        "    # modify the default parameters of np.load\n",
        "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "    \n",
        "    (x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words = max_features)\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
        "    x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
        "    self.x_train, self.y_train = x_train, y_train\n",
        "    self.x_test, self.y_test = x_test[:1000, :], y_test[:1000]\n",
        "    np.load = np_load_old\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEWmirQgCXQq"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb-DvyP0CUhj"
      },
      "source": [
        "class LSTM(models.Model):\n",
        "  def __init__(self, max_features, maxlen):\n",
        "    x = layers.Input((maxlen,))\n",
        "    h = layers.Embedding(max_features, 64)(x)\n",
        "    h = layers.LSTM(32, dropout = .2, recurrent_dropout = .2)(h)\n",
        "    y = layers.Dense(1, activation = 'sigmoid')(h)\n",
        "    super().__init__(x, y)\n",
        "    \n",
        "    self.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpKL312a92J9"
      },
      "source": [
        "## Note\n",
        "\n",
        "### Check number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_tr-m0bopyJ",
        "outputId": "a1d8f233-2a65-4d74-93e2-a1673e56959e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "ls = LSTM(max_features = 10000, maxlen = 80)\n",
        "ls.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 80, 64)            640000    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 652,449\n",
            "Trainable params: 652,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVvnzlc78YO9",
        "outputId": "9765c854-e029-4e95-9315-87db0b6938ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# embedding\n",
        "w_emb = 10000 * 64\n",
        "\n",
        "# LSTM\n",
        "w_xh = 64 * 32 * 4\n",
        "w_hh = 32 * 32 * 4 \n",
        "b_h = 32 *4\n",
        "\n",
        "print('LSTM Param = {}'.format(w_xh + w_hh + b_h))\n",
        "\n",
        "#dense layer\n",
        "dense_4 = 32 + 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBPPiypSCfPx"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqSGB5gSCaij"
      },
      "source": [
        "class Machine:\n",
        "  def __init__(self, model = LSTM, max_features = 10000, maxlen = 80):\n",
        "    self.data = Data(max_features, maxlen)\n",
        "    self.model = model(max_features, maxlen)\n",
        "    \n",
        "  def run(self, epoch = 3, batch_size = 32):\n",
        "    data = self.data\n",
        "    model = self.model\n",
        "    \n",
        "    print('Training stage')\n",
        "    model.fit(data.x_train, data.y_train, batch_size = batch_size,\n",
        "              epochs = epoch, validation_data = (data.x_test, data.y_test),\n",
        "              verbose = 2)\n",
        "    \n",
        "    loss, acc = model.evaluate(data.x_test, data.y_test, batch_size = batch_size, verbose = 2)\n",
        "    \n",
        "    print('Test performance: accuracy = {0}, loss = {1}'.format(acc, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGPZbn_dChNp"
      },
      "source": [
        "# Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFzuuhKqay_1",
        "outputId": "6eccf78c-2485-4f85-a8bf-21a904b42a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "m = Machine()\n",
        "m.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0812 05:56:47.413540 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0812 05:56:47.438755 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0812 05:56:47.443462 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0812 05:56:47.602604 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0812 05:56:47.622495 140657280669568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0812 05:56:48.147904 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0812 05:56:48.186589 140657280669568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0812 05:56:48.196864 140657280669568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training stage\n",
            "Train on 25000 samples, validate on 1000 samples\n",
            "Epoch 1/3\n",
            " - 253s - loss: 0.4770 - acc: 0.7734 - val_loss: 0.3575 - val_acc: 0.8440\n",
            "Epoch 2/3\n",
            " - 246s - loss: 0.3339 - acc: 0.8603 - val_loss: 0.3583 - val_acc: 0.8300\n",
            "Epoch 3/3\n",
            " - 226s - loss: 0.2753 - acc: 0.8886 - val_loss: 0.3850 - val_acc: 0.8350\n",
            "Test performance: accuracy = 0.835, loss = 0.38503733015060426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsuIreiC4fr"
      },
      "source": [
        "## Check prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtzNUtaPC25E",
        "outputId": "68f40662-eb08-4259-cabb-501163073078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_hat = m.model.predict(m.data.x_test[:2,:])\n",
        "y = m.data.y_test[:2]\n",
        "for (a,b) in zip(y, y_hat):\n",
        "  print('y = {}, y_hat = {}'.format(a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 0, y_hat = [0.19915646]\n",
            "y = 1, y_hat = [0.97466034]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ8IGjLoCoI4"
      },
      "source": [
        "# Define Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1CPLesJdxCn"
      },
      "source": [
        "class BI_LSTM(models.Model):\n",
        "  def __init__(self, max_features, maxlen):\n",
        "    \n",
        "    x = layers.Input((maxlen,))\n",
        "    h = layers.Embedding(max_features, 64)(x)\n",
        "    h = layers.Bidirectional(layers.LSTM(16, dropout = .2, recurrent_dropout = .2))(h)\n",
        "    y = layers.Dense(1, activation = 'sigmoid')(h)\n",
        "    super().__init__(x, y)\n",
        "    \n",
        "    self.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNW2A0sKCy7t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parM-7N0DC3J"
      },
      "source": [
        "# Train Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8LSw2PgF5Y",
        "outputId": "a24c8d69-faaf-43f2-f45e-44097617b88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "m1 = Machine(model = BI_LSTM)\n",
        "m1.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training stage\n",
            "Train on 25000 samples, validate on 1000 samples\n",
            "Epoch 1/3\n",
            " - 445s - loss: 0.4689 - acc: 0.7763 - val_loss: 0.3624 - val_acc: 0.8330\n",
            "Epoch 2/3\n",
            " - 463s - loss: 0.3089 - acc: 0.8736 - val_loss: 0.3651 - val_acc: 0.8450\n",
            "Epoch 3/3\n",
            " - 467s - loss: 0.2419 - acc: 0.9028 - val_loss: 0.3890 - val_acc: 0.8330\n",
            "Test performance: accuracy = 0.833, loss = 0.3889838485121727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsZmGIWsvzCD"
      },
      "source": [
        "### Check prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4pggqzO9gGQ",
        "outputId": "cc729544-02eb-4b86-d9e8-2a00debf7e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_hat = m1.model.predict(m1.data.x_test[20:22,:])\n",
        "y = m.data.y_test[20:22]\n",
        "for (a,b) in zip(y, y_hat):\n",
        "  print('y = {}, y_hat = {}'.format(a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 1, y_hat = [0.9979255]\n",
            "y = 1, y_hat = [0.9850507]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOR-kmvov2qB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}